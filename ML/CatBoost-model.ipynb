{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3887,"databundleVersionId":32350,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================================================\n# HIGGS BOSON â€” CatBoost Only + t-SNE Visualization (Before vs After)\n# ===============================================================\n\nimport os, math, zipfile\nimport numpy as np\nimport pandas as pd\nimport random\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier, Pool\n\n# ---------------- Settings ----------------\nDEVICE = 'cuda'\nSEED = 42\nnp.random.seed(SEED)\nrandom.seed(SEED)\nN_FOLDS = 5\n\n# ---------------- Kaggle File Handling ----------------\nzip_files = {\n    \"train\": \"/kaggle/input/higgs-boson/training.zip\",\n    \"test\":  \"/kaggle/input/higgs-boson/test.zip\",\n    \"submission\": \"/kaggle/input/higgs-boson/random_submission.zip\"\n}\nextract_dir = \"/kaggle/working/higgs_data/\"\nos.makedirs(extract_dir, exist_ok=True)\nfor key, path in zip_files.items():\n    if os.path.exists(path):\n        with zipfile.ZipFile(path, \"r\") as z:\n            z.extractall(extract_dir)\n            print(f\"{key} unzipped.\")\n    else:\n        print(f\"{key} zip not found at {path}\")\n\nTRAIN_CSV = os.path.join(extract_dir, \"training.csv\")\nTEST_CSV  = os.path.join(extract_dir, \"test.csv\")\nOUT_SUB  = \"/kaggle/working/submission.csv\"\n\n# ---------------- AMS Metric ----------------\ndef ams_score(s, b):\n    b_reg = 10.0\n    rad = 2.0 * ((s + b + b_reg) * math.log(1.0 + s / (b + b_reg)) - s)\n    return math.sqrt(rad) if rad > 0 else 0.0\n\n# ---------------- Load Data ----------------\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df  = pd.read_csv(TEST_CSV)\n\ntrain_df.replace(-999.0, np.nan, inplace=True)\ntest_df.replace(-999.0, np.nan, inplace=True)\n\nfor c in train_df.columns:\n    if c in ['EventId','Weight','Label']: continue\n    if train_df[c].isna().any():\n        train_df[c+'_miss'] = train_df[c].isna().astype(int)\n        test_df[c+'_miss']  = test_df[c].isna().astype(int)\n\nnumeric_cols = [c for c in train_df.select_dtypes(include=np.number).columns if c != \"Weight\"]\ntrain_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].median())\nnum_cols_test = [c for c in numeric_cols if c in test_df.columns]\ntest_df[num_cols_test] = test_df[num_cols_test].fillna(train_df[num_cols_test].median())\n\n# Add derived features\nif {'DER_mass_MMC','DER_mass_vis'}.issubset(train_df.columns):\n    train_df['mass_ratio'] = train_df['DER_mass_MMC']/(train_df['DER_mass_vis']+1e-6)\n    test_df['mass_ratio']  = test_df['DER_mass_MMC']/(test_df['DER_mass_vis']+1e-6)\nif {'PRI_tau_pt','PRI_met'}.issubset(train_df.columns):\n    train_df['pt_ratio'] = train_df['PRI_tau_pt']/(train_df['PRI_met']+1e-6)\n    test_df['pt_ratio']  = test_df['PRI_tau_pt']/(test_df['PRI_met']+1e-6)\n\ny = (train_df['Label'] == 's').astype(int).values\nweights = train_df['Weight'].values\nevent_ids_test = test_df['EventId'].values\n\ntrain_features = train_df.drop(columns=['EventId','Weight','Label'], errors='ignore')\ntest_features  = test_df.drop(columns=['EventId'], errors='ignore')\n\nscaler = StandardScaler()\nX = scaler.fit_transform(train_features.values.astype(np.float32))\nX_test = scaler.transform(test_features.values.astype(np.float32))\n\nkf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\n# ---------------- CatBoost Only ----------------\nprint(\"\\n=== CatBoost Only ===\")\noof_cat = np.zeros(len(X))\ntest_pred_cat_folds = []\nmodels = []\n\nfor fold, (tr, va) in enumerate(kf.split(X, y)):\n    print(f\"\\n----- Fold {fold+1}/{N_FOLDS} -----\")\n    model = CatBoostClassifier(\n        iterations=1200,\n        learning_rate=0.01,\n        depth=8,\n        l2_leaf_reg=3.0,\n        bootstrap_type='Poisson',  # valid GPU-friendly subsampling\n        bagging_temperature=1.0,\n        random_seed=SEED + fold,\n        eval_metric='AUC',\n        task_type='GPU' if DEVICE == 'cuda' else 'CPU',\n        verbose=100,\n        early_stopping_rounds=50\n    )\n\n    train_pool = Pool(X[tr], y[tr])\n    valid_pool = Pool(X[va], y[va])\n    model.fit(train_pool, eval_set=valid_pool)\n    \n    val_pred = model.predict_proba(X[va])[:, 1]\n    fold_auc = roc_auc_score(y[va], val_pred)\n    print(f\"Fold {fold+1} AUC: {fold_auc:.4f}\")\n\n    oof_cat[va] = val_pred\n    test_pred_cat_folds.append(model.predict_proba(X_test)[:, 1])\n    models.append(model)\n\ntest_pred_cat = np.mean(test_pred_cat_folds, axis=0)\ncv_auc = roc_auc_score(y, oof_cat)\nprint(f\"\\nOverall CV AUC: {cv_auc:.4f}\")\n\n# ---------------- AMS ----------------\nthr_range = np.linspace(0.01, 0.99, 99)\nbest_thr, best_ams = 0.5, -1\nfor t in thr_range:\n    s = weights[(y == 1) & (oof_cat > t)].sum()\n    b = weights[(y == 0) & (oof_cat > t)].sum()\n    sc = ams_score(s, b)\n    if sc > best_ams:\n        best_ams, best_thr = sc, t\nprint(f\"Best AMS on CatBoost OOF = {best_ams:.3f} @ thr={best_thr:.4f}\")\n\n# ---------------- t-SNE Visualization ----------------\nprint(\"\\nGenerating t-SNE visualizations...\")\n\nmax_samples = 5000\nidx_sample = np.random.choice(len(X), size=min(max_samples, len(X)), replace=False)\nX_sample = X[idx_sample]\ny_sample = y[idx_sample]\n\nprint(\"Running t-SNE on original features...\")\ntsne_before = TSNE(n_components=2, random_state=SEED, perplexity=30, n_iter=1000)\nemb_before = tsne_before.fit_transform(X_sample)\n\nprint(\"Generating CatBoost leaf embeddings...\")\nleaf_indices = models[0].calc_leaf_indexes(X_sample)\nfor m in models[1:]:\n    leaf_indices = np.hstack([leaf_indices, m.calc_leaf_indexes(X_sample)])\n\nprint(\"Running t-SNE on CatBoost leaf embeddings...\")\ntsne_after = TSNE(n_components=2, random_state=SEED, perplexity=30, n_iter=1000)\nemb_after = tsne_after.fit_transform(leaf_indices)\n\nfig, axs = plt.subplots(1, 2, figsize=(14, 6))\naxs[0].scatter(emb_before[:, 0], emb_before[:, 1], c=y_sample, cmap='coolwarm', s=10, alpha=0.7)\naxs[0].set_title(\"t-SNE Before Training (Raw Features)\")\naxs[0].set_xlabel(\"Dim 1\")\naxs[0].set_ylabel(\"Dim 2\")\n\naxs[1].scatter(emb_after[:, 0], emb_after[:, 1], c=y_sample, cmap='coolwarm', s=10, alpha=0.7)\naxs[1].set_title(\"t-SNE After CatBoost (Leaf Embeddings)\")\naxs[1].set_xlabel(\"Dim 1\")\naxs[1].set_ylabel(\"Dim 2\")\n\nplt.tight_layout()\nplt.show()\n\n# ---------------- Submission ----------------\nprint(\"\\nWriting submission...\")\nrankorder = np.argsort(np.argsort(test_pred_cat)) + 1\nclasses = np.where(test_pred_cat > best_thr, 's', 'b')\nsub = pd.DataFrame({\"EventId\": event_ids_test, \"RankOrder\": rankorder, \"Class\": classes})\nsub.to_csv(OUT_SUB, index=False)\nprint(\"Saved submission to:\", OUT_SUB)\nprint(\"Final CatBoost AMS:\", best_ams)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:58:59.080568Z","iopub.execute_input":"2025-10-28T18:58:59.081543Z","iopub.status.idle":"2025-10-28T19:01:11.417138Z","shell.execute_reply.started":"2025-10-28T18:58:59.081508Z","shell.execute_reply":"2025-10-28T19:01:11.416232Z"}},"outputs":[],"execution_count":null}]}