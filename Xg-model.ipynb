{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3887,"databundleVersionId":32350,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================================================\n# HIGGS BOSON â€” XGBoost only\n# ===============================================================\n\nimport os, math, zipfile\nimport numpy as np\nimport pandas as pd\nimport random\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\n\n# ---------------- Settings ----------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\nN_FOLDS = 5\n\n# ---------------- Kaggle File Handling ----------------\nzip_files = {\n    \"train\": \"/kaggle/input/higgs-boson/training.zip\",\n    \"test\":  \"/kaggle/input/higgs-boson/test.zip\",\n    \"submission\": \"/kaggle/input/higgs-boson/random_submission.zip\"\n}\nextract_dir = \"/kaggle/working/higgs_data/\"\nos.makedirs(extract_dir, exist_ok=True)\nfor key, path in zip_files.items():\n    if os.path.exists(path):\n        with zipfile.ZipFile(path, \"r\") as z:\n            z.extractall(extract_dir)\n            print(f\"{key} unzipped.\")\n    else:\n        print(f\"{key} zip not found at {path}\")\n\nTRAIN_CSV = os.path.join(extract_dir, \"training.csv\")\nTEST_CSV  = os.path.join(extract_dir, \"test.csv\")\nOUT_SUB  = \"/kaggle/working/submission.csv\"\n\n# ---------------- AMS Metric ----------------\ndef ams_score(s, b):\n    b_reg = 10.0\n    rad = 2.0 * ((s + b + b_reg) * math.log(1.0 + s / (b + b_reg)) - s)\n    return math.sqrt(rad) if rad > 0 else 0.0\n\n# ---------------- Load Data ----------------\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df  = pd.read_csv(TEST_CSV)\n\n# Replace missing sentinel and create missing flags\ntrain_df.replace(-999.0, np.nan, inplace=True)\ntest_df.replace(-999.0, np.nan, inplace=True)\n\nfor c in train_df.columns:\n    if c in ['EventId','Weight','Label']: continue\n    if train_df[c].isna().any():\n        train_df[c+'_miss'] = train_df[c].isna().astype(int)\n        test_df[c+'_miss']  = test_df[c].isna().astype(int)\n\nnumeric_cols = [c for c in train_df.select_dtypes(include=np.number).columns if c != \"Weight\"]\ntrain_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].median())\nnum_cols_test = [c for c in numeric_cols if c in test_df.columns]\ntest_df[num_cols_test] = test_df[num_cols_test].fillna(train_df[num_cols_test].median())\n\n# Add derived features (same as original)\nif {'DER_mass_MMC','DER_mass_vis'}.issubset(train_df.columns):\n    train_df['mass_ratio'] = train_df['DER_mass_MMC']/(train_df['DER_mass_vis']+1e-6)\n    test_df['mass_ratio']  = test_df['DER_mass_MMC']/(test_df['DER_mass_vis']+1e-6)\nif {'PRI_tau_pt','PRI_met'}.issubset(train_df.columns):\n    train_df['pt_ratio'] = train_df['PRI_tau_pt']/(train_df['PRI_met']+1e-6)\n    test_df['pt_ratio']  = test_df['PRI_tau_pt']/(test_df['PRI_met']+1e-6)\n\n# Targets, weights, ids\ny = (train_df['Label'] == 's').astype(int).values\nweights = train_df['Weight'].values\nevent_ids_test = test_df['EventId'].values\n\n# Features\ntrain_features = train_df.drop(columns=['EventId','Weight','Label'], errors='ignore')\ntest_features  = test_df.drop(columns=['EventId'], errors='ignore')\n\n# Scaling (same as original)\nscaler = StandardScaler()\nX = scaler.fit_transform(train_features.values.astype(np.float32))\nX_test = scaler.transform(test_features.values.astype(np.float32))\n\nkf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\n# ---------------- Containers ----------------\noof_xgb = np.zeros(len(X))\ntest_pred_xgb_folds = []\n\n# ---------------- XGBoost (only model) ----------------\nprint(\"\\n=== XGBoost ===\")\nfor fold, (tr_idx, va_idx) in enumerate(kf.split(X, y)):\n    print(f\"\\n--- Fold {fold+1}/{N_FOLDS} ---\")\n    X_tr, X_va = X[tr_idx], X[va_idx]\n    y_tr, y_va = y[tr_idx], y[va_idx]\n    w_tr, w_va = weights[tr_idx], weights[va_idx]\n\n    xgbm = xgb.XGBClassifier(\n        n_estimators=1200,\n        learning_rate=0.01,\n        max_depth=6,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        reg_lambda=1.0,\n        use_label_encoder=False,\n        tree_method='hist',\n        eval_metric='auc',\n        random_state=SEED\n    )\n\n    # Fit with early stopping using evaluation set, pass sample weights if desired\n    xgbm.fit(\n        X_tr, y_tr,\n        sample_weight=w_tr,\n        eval_set=[(X_va, y_va)],\n        early_stopping_rounds=50,\n        verbose=100\n    )\n\n    # OOF and test predictions\n    oof_xgb[va_idx] = xgbm.predict_proba(X_va)[:,1]\n    test_pred_xgb_folds.append(xgbm.predict_proba(X_test)[:,1])\n\n# Average test predictions across folds\ntest_pred_xgb = np.mean(test_pred_xgb_folds, axis=0)\n\n# ---------------- Evaluation & Threshold search (AMS) ----------------\nthr_range = np.linspace(0.01, 0.99, 99)\nbest_thr, best_ams = 0.5, -1\nfor t in thr_range:\n    s = weights[(y==1) & (oof_xgb > t)].sum()\n    b = weights[(y==0) & (oof_xgb > t)].sum()\n    sc = ams_score(s, b)\n    if sc > best_ams:\n        best_ams, best_thr = sc, t\n\nprint(f\"\\nBest AMS on XGBoost OOF = {best_ams:.6f} @ thr={best_thr:.4f}\")\nprint(\"CV AUC (OOF):\", roc_auc_score(y, oof_xgb))\n\n# ---------------- Submission ----------------\nprint(\"\\nWriting submission...\")\nrankorder = np.argsort(np.argsort(test_pred_xgb)) + 1\nclasses = np.where(test_pred_xgb > best_thr, 's', 'b')\nsub = pd.DataFrame({\"EventId\": event_ids_test, \"RankOrder\": rankorder, \"Class\": classes})\nsub.to_csv(OUT_SUB, index=False)\nprint(\"Saved submission to:\", OUT_SUB)\nprint(\"Done.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-28T17:38:39.029317Z","iopub.execute_input":"2025-10-28T17:38:39.029608Z"}},"outputs":[{"name":"stdout","text":"train unzipped.\ntest unzipped.\nsubmission unzipped.\n\n=== XGBoost ===\n\n--- Fold 1/5 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-auc:0.77143\n[100]\tvalidation_0-auc:0.84352\n[200]\tvalidation_0-auc:0.85335\n[300]\tvalidation_0-auc:0.86197\n[400]\tvalidation_0-auc:0.86924\n[500]\tvalidation_0-auc:0.87583\n[600]\tvalidation_0-auc:0.88061\n[700]\tvalidation_0-auc:0.88304\n[800]\tvalidation_0-auc:0.88533\n[900]\tvalidation_0-auc:0.88703\n[1000]\tvalidation_0-auc:0.88856\n[1100]\tvalidation_0-auc:0.88967\n[1199]\tvalidation_0-auc:0.89057\n\n--- Fold 2/5 ---\n[0]\tvalidation_0-auc:0.76911\n[100]\tvalidation_0-auc:0.84912\n[200]\tvalidation_0-auc:0.85767\n[300]\tvalidation_0-auc:0.86524\n[400]\tvalidation_0-auc:0.87303\n[500]\tvalidation_0-auc:0.87891\n[600]\tvalidation_0-auc:0.88312\n[700]\tvalidation_0-auc:0.88572\n[800]\tvalidation_0-auc:0.88785\n[900]\tvalidation_0-auc:0.88983\n[1000]\tvalidation_0-auc:0.89128\n[1100]\tvalidation_0-auc:0.89239\n[1199]\tvalidation_0-auc:0.89330\n\n--- Fold 3/5 ---\n[0]\tvalidation_0-auc:0.77058\n[100]\tvalidation_0-auc:0.84759\n[200]\tvalidation_0-auc:0.85654\n[300]\tvalidation_0-auc:0.86445\n[400]\tvalidation_0-auc:0.87232\n[500]\tvalidation_0-auc:0.87896\n[600]\tvalidation_0-auc:0.88319\n[700]\tvalidation_0-auc:0.88585\n[800]\tvalidation_0-auc:0.88818\n[900]\tvalidation_0-auc:0.88989\n[1000]\tvalidation_0-auc:0.89111\n[1100]\tvalidation_0-auc:0.89227\n[1199]\tvalidation_0-auc:0.89322\n\n--- Fold 4/5 ---\n[0]\tvalidation_0-auc:0.76700\n[100]\tvalidation_0-auc:0.84827\n[200]\tvalidation_0-auc:0.85671\n[300]\tvalidation_0-auc:0.86492\n","output_type":"stream"}],"execution_count":null}]}